{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "45fbb33b",
      "metadata": {
        "id": "45fbb33b"
      },
      "source": [
        "# LangChain Tutorial Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34a0df42",
      "metadata": {
        "id": "34a0df42"
      },
      "source": [
        "\n",
        "In this notebook, you will practice using LangChain to interact with large language models (LLMs),\n",
        "build chains, agents, and utilize memory. Fill in the code blocks with your implementations.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community langchain-groq duckduckgo-search geopy requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-2qSQcOGWyQ",
        "outputId": "56d75597-8291-491f-f5e4-d0c6caced0e4"
      },
      "id": "C-2qSQcOGWyQ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.10/dist-packages (6.2.11)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.10/dist-packages (2.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.121)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.5.2)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.11.0)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Requirement already satisfied: primp>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (0.6.2)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy) (2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.3)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "169dd23c",
      "metadata": {
        "id": "169dd23c"
      },
      "source": [
        "## Exercise 1: Basic LLM Query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf03f4a7",
      "metadata": {
        "id": "bf03f4a7"
      },
      "source": [
        "In this exercise, you will set up a basic interaction with the GROQ LLaMA model using LangChain.\n",
        "\n",
        "1. Initialize the LLM (Use GROQ and chose LLM).\n",
        "2. Create a prompt that asks the LLM to generate a story about a topic.\n",
        "3. Run the LLM chain to retrieve the response.\n",
        "\n",
        "**Steps**:\n",
        "- Import required modules from `langchain`.\n",
        "- Initialize the LLM with your GROQ API key.\n",
        "- Create a prompt template that takes a topic as input.\n",
        "- Create an LLM Chain and run it to get a response.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key=\"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\""
      ],
      "metadata": {
        "id": "J_vQft4bUB8I"
      },
      "id": "J_vQft4bUB8I",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5686ae2f",
      "metadata": {
        "id": "5686ae2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b69fde-11c2-410a-9de6-b4bf4326e966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "لم يكن هناك مثل هذه الأيام في المدينة حيث تجمعنا بعدد من الأصدقاء بكل ما فيهم من طموح و прохة. أعدنا خطواتنا وسارنا بصدق نحو قاعة المنتزه التي كانت تحتضننا وأصدقائنا.\n",
            "\n",
            "كانت ريم هي الافضل من بيننا جميعا، لا بل حتى أكثر من ذلك. كان لها القدرة على خلق ما لا يوجد في تفكيرنا، وابتكار ما لم نکن للمرة الأولى. وكانت دائما مسرعة إلى مساعدتنا، وتحمل الأعباء من على ظهرنا.\n",
            "\n",
            "أنا وأصدقائي، كنا نرتدي أزياءنا المميزة وقبلنا نحو قاعة المنتزه، وغمسنا فيها كل قوتنا. لقد لاحظنا ريم وهي تأتي نحوهنا، وباتت تشد إحساسنا نحو الصدق، فكانت دائما التى تحملنا على تحقيق الأهداف.\n",
            "\n",
            "لم تکن يوما باردة للغاية بمدينةنا حتى لاحظنا ريم وهي تأتي نحونا، وكانت بكل هدوء تحمل معها قفازين كبيرين على ملابسها، وشاربتيها التي كانت ملحقة بتخمة متعددة، كانت رائعة على المبكرة بكل هذه الالتواءات. ولم تکن ذرى المبكرة باردة أو ساخنة، بل لاحت عليه ظهرها مثل البرق.\n",
            "\n",
            "لم یکن لها أصراع على الخطأ، ولم یکن فيها دهور كادها لا تنتهى، بل كانت دائما الصالحة المطروزة، وأحسنها، وذات نفس صاف. وكانت ريم دائما تسعدنا، وكانت كل ما يبابنا من العقل يأتي منها، وبكل ما في الطاقات التي فيها. \n",
            "\n",
            "ومن يومئ الكون بمصاد متشابهة كل هذه الأمور، بل كان كما يلي:\n",
            "\n",
            "- كنا جميعا مدركين أهمية هى الافضل والمميزة من بيننا جميعا، ونحن جميعا ذاهبون نحو قاعة المنتزه من ظهر اليوم، وبكل ما فينا من طموح ومتعة.\n",
            "\n",
            "- وذروا بكل ما يبابنا، وذروا بكل ما لدينا، وذروا هبة وصحابة وطموح في المجموع، وذروا بكل هذه الأشياء في قاعة المنتزه.\n",
            "\n",
            "- وصولا حتى أن من كان يناظرها في قاعة المنتزه كان كل ما يبابنا يكون من ريم، وبكل ما لدينا في الأمة. \n",
            "\n",
            "وهكذا لاحظنا ريم وهي تأتي نحونا، وكانت بكل هدوء، وبكل ما فيها من صابرة، وكانت بكل هدوء بكل ما فينا من أهداف، وبكل ما لدينا من طموح، وبكل ما لدينا من هبوط.\n",
            "\n",
            "بل لاحظنا ريم وهي تأتي نحونا، وكانت بكل هدوء، وبكل ما فينا من صابرة، وبكل ما لدينا من هبوط، وبكل ما يبابنا من هبوط، وبكل ما لدينا من هبوط.\n",
            "\n",
            "وصلنا جميعا إلى قاعة المنتزه، وبكل ما لدينا من هدوء، وبكل ما لدينا من هدوء، وبكل ما لدينا من هدوء، وبكل ما لدينا من هدوء، وبكل ما لدينا من هدوء.\n",
            "\n",
            "وما اذا كانت ريم هي الافضل، وبكل ما لدينا من هدوء، وبكل ما لدينا من هدوء، وبكل ما لدينا من هدوء، وبكل ما لدينا من هدوء، وبكل ما لدينا من هدوء.\n",
            "\n",
            "وما اذا كانت ريم هي الافضل، وبكل ما لدينا من هدوء، وبكل ما لدينا من هدوء، وبكل ما لدينا من هدوء، وبكل ما لدينا من هدوء، وبكل ما لدينا من هدوء.\n"
          ]
        }
      ],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.8,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    api_key=groq_api_key\n",
        ")\n",
        "\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Write a short story about {topic}.\"\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "response = chain.run(\"ريم هي الافضل\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ff1b3fa",
      "metadata": {
        "id": "1ff1b3fa"
      },
      "source": [
        "## Exercise 2: Building a Conversational Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a6a1f26",
      "metadata": {
        "id": "4a6a1f26"
      },
      "source": [
        "\n",
        "In this exercise, you will create a conversational agent that can interact with a user, make decisions,\n",
        "and use external tools like a search tool.\n",
        "\n",
        "1. Define a tool.\n",
        "2. Create an agent that can decide whether to use the tool or interact with the LLM.\n",
        "3. Run the agent with various inputs.\n",
        "\n",
        "**Steps**:\n",
        "- Define the search tool using a function.\n",
        "- Initialize an agent using the tool and the LLM.\n",
        "- Run the agent with sample inputs.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a6e3e8e2",
      "metadata": {
        "id": "a6e3e8e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00593237-23c9-4acb-a6c4-2d17c387e2f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-386a91cd0650>:8: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  agent = initialize_agent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent stopped due to iteration limit or time limit.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "search = DuckDuckGoSearchRun()\n",
        "\n",
        "tools = [search]\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")\n",
        "response = agent.run(\"Find information about Queen reem.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf94d2f",
      "metadata": {
        "id": "3cf94d2f"
      },
      "source": [
        "## Exercise 3: Using LLM as Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53ff48d9",
      "metadata": {
        "id": "53ff48d9"
      },
      "source": [
        "\n",
        "In this exercise, you will use an LLM to summarize and retain information from conversations.\n",
        "\n",
        "1. Set up LLM-based memory.\n",
        "2. Create a conversation with the LLM and memory.\n",
        "3. Ask follow-up questions using memory to retrieve past context.\n",
        "\n",
        "**Steps**:\n",
        "- Initialize summarization-based memory.\n",
        "- Run a few queries and retrieve responses.\n",
        "- Ask follow-up questions that reference previous interactions.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "796557b9",
      "metadata": {
        "id": "796557b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f90dc6-467b-497b-d342-8d8066a81d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-5915cbfc3aa0>:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
            "  chain = ConversationChain(llm=llm, memory=memory)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Response: I chose the number 17. That's a fascinating number, by the way. Did you know that 17 is a Heptadecagon, a polygon with 17 sides? It's also a prime number, which means it can only be divided by 1 and itself. In fact, 17 is the eighth prime number and is often referred to as the first \"interesting\" prime number.\n",
            "Second Response: I chose the number 8. That's an interesting choice, considering it's the second-smallest tetractys, which is a triangular array of eight dots, similar to the structure of some atomic nuclei. Did you know that 8 is also a power of 2, which is the basis of binary code used in computers? It's also a significant number in many cultures and traditions, including the octagonal shape of some buildings and the eight-pointed star, which is often associated with prosperity and good fortune.\n",
            "Third Response: We previously discussed the numbers 17 and 8. The first one is a Heptadecagon, a polygon with 17 sides, and the second one is a significant number in various cultures and traditions, associated with the octagonal shape of buildings and the eight-pointed star.\n",
            "\n",
            "Now, if we want to find the result of adding these two numbers, we would calculate 17 + 8.\n",
            "\n",
            "Let me do some calculations... \n",
            "\n",
            "17 + 8 = 25\n",
            "\n",
            "So, the result of adding the two numbers is 25. That's an interesting number, by the way. Did you know that 25 is a square number, which means it can be expressed as the square of another number (5^2)? It's also a significant number in music, as it's the number of half-steps in a musical octave.\n"
          ]
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import ConversationChain\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "memory.clear()\n",
        "\n",
        "chain = ConversationChain(llm=llm, memory=memory)\n",
        "\n",
        "res1 = chain.run(\"choose any odd number\")\n",
        "res2 = chain.run(\"choose any even number\")\n",
        "res3 = chain.run(\"From the previous conversations. What was these numbers and what is the result of adding them ?\")\n",
        "\n",
        "print(f'First Response: {res1}\\nSecond Response: {res2}\\nThird Response: {res3}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "630fe2fb",
      "metadata": {
        "id": "630fe2fb"
      },
      "source": [
        "## Exercise 4: Combining Tools and Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17dba76c",
      "metadata": {
        "id": "17dba76c"
      },
      "source": [
        "\n",
        "In this final exercise, you will build an intelligent agent that can use both tools (like an API) and memory.\n",
        "\n",
        "1. Define an external tool (like a weather API).\n",
        "2. Set up an agent that uses both the tool and LLM memory.\n",
        "3. Interact with the agent, combining memory and external data.\n",
        "\n",
        "**Steps**:\n",
        "- Define a weather API tool (mock or real API).\n",
        "- Initialize the agent with memory and the tool.\n",
        "- Run the agent with inputs, and check how it uses both memory and tools.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5e11ad68",
      "metadata": {
        "id": "5e11ad68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90c97fb-3723-44b6-c192-4e2dba8066fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Response: I chose the number 23. That's a fascinating number, by the way. Did you know that 23 is a strange and interesting number in mathematics, often referred to as the \"Scottish numeral\" due to its unique position in the decimal system? It's also a prime number, which means it can only be divided by 1 and itself. In fact, 23 is the eighth prime number that is not only prime but also the sum of two consecutive prime numbers: 23 = 11 + 12. The number 23 is also associated with the play \"Waiting for Godot\" by Samuel Beckett, where two characters, Vladimir and Estragon, wait for someone who never arrives. They wait for 23 years, but it's not clear if they actually wait the entire time. The play explores the concept of time and the human experience.\n",
            "Second Response: I chose the number 42. That's a fascinating number, by the way. Did you know that 42 is the answer to the ultimate question of life, the universe, and everything, according to Douglas Adams' science fiction series \"The Hitchhiker's Guide to the Galaxy\"? It's also a significant number in mathematics, as it's a highly composite number, which means it has a large number of factors. In fact, 42 has 9 factors: 1, 2, 3, 6, 7, 14, 21, 42. This makes it one of the few numbers that is both a highly composite number and a highly totient number, which is a number with a large number of possible multiples. Additionally, 42 is a significant number in astronomy, as it's the number of years it takes the planet Jupiter to complete one orbit around the Sun in its current orbit.\n",
            "\n",
            "Now that we've chosen the two numbers, one odd and one even, let's recall what we previously discussed. We chose the numbers 23 and 42. If we want to find the result of adding these two numbers, we would calculate 23 + 42.\n",
            "\n",
            "Let me do some calculations... \n",
            "\n",
            "23 + 42 = 65\n",
            "\n",
            "So, the result of adding the two numbers is 65. That's an interesting number, by the way. Did you know that 65 is a relatively prime number to many other numbers, particularly in the decimal system?\n",
            "Third Response: We previously discussed the numbers 23 and 42. The first one is a strange and interesting number in mathematics, often referred to as the \"Scottish numeral\" due to its unique position in the decimal system, and the second one is the answer to the ultimate question of life, the universe, and everything, according to Douglas Adams' science fiction series \"The Hitchhiker's Guide to the Galaxy\".\n",
            "\n",
            "If we want to find the result of adding these two numbers, we would calculate 23 + 42.\n",
            "\n",
            "Let me do some calculations... \n",
            "\n",
            "23 + 42 = 65\n",
            "\n",
            "So, the result of adding the two numbers is 65. That's an interesting number, by the way. Did you know that 65 is a relatively prime number to many other numbers, particularly in the decimal system?\n"
          ]
        }
      ],
      "source": [
        "from langchain.memory import ConversationSummaryMemory\n",
        "from langchain import ConversationChain\n",
        "\n",
        "summary_memory = ConversationSummaryMemory(llm=llm)\n",
        "\n",
        "summary_memory.clear()\n",
        "\n",
        "chain_with_buffer_memory = ConversationChain(llm=llm, memory=summary_memory)\n",
        "res1 = chain.run(\"choose any odd number\")\n",
        "res2 = chain.run(\"choose any even number\")\n",
        "res3 = chain.run(\"From the previous conversations. What was these numbers and what is the result of adding them ?\")\n",
        "\n",
        "print(f'First Response: {res1}\\nSecond Response: {res2}\\nThird Response: {res3}')"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}